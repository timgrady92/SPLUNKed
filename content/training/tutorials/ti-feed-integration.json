{
  "id": "ti-feed-integration",
  "type": "tutorial",
  "title": "Threat Feed Integration",
  "description": "Integrate external threat feeds including STIX/TAXII protocols, scheduled feed updates, feed normalization, and aggregating multiple intelligence sources.",
  "category": "threat-intel",
  "difficulty": "advanced",
  "duration": "25 min",
  "tags": ["threat-intel", "stix", "taxii", "feeds", "advanced"],
  "objectives": [
    "Understand STIX/TAXII threat intelligence standards",
    "Configure scheduled feed updates",
    "Normalize feeds from different sources",
    "Aggregate multiple feeds into unified lookups"
  ],
  "content": {
    "sections": [
      {
        "title": "Threat Feed Landscape",
        "body": "<p>External threat feeds provide indicators from sources beyond your organization.</p><h4>Feed Categories</h4><table><tr><th>Category</th><th>Examples</th><th>Typical Content</th></tr><tr><td>Commercial</td><td>Recorded Future, Mandiant, CrowdStrike</td><td>Curated IOCs with context</td></tr><tr><td>Open Source</td><td>Abuse.ch, AlienVault OTX, PhishTank</td><td>Community-contributed IOCs</td></tr><tr><td>Government</td><td>US-CERT, CISA, NCSC</td><td>Advisory-based indicators</td></tr><tr><td>Industry</td><td>FS-ISAC, H-ISAC</td><td>Sector-specific threats</td></tr><tr><td>Vendor</td><td>Microsoft, Cisco Talos</td><td>Product-specific intelligence</td></tr></table><h4>Feed Formats</h4><ul><li><strong>STIX/TAXII</strong>: Industry standard, structured</li><li><strong>CSV</strong>: Simple, widely supported</li><li><strong>JSON</strong>: Flexible, modern APIs</li><li><strong>Plain text</strong>: IP/domain lists</li></ul>"
      },
      {
        "title": "STIX/TAXII Fundamentals",
        "body": "<h4>STIX (Structured Threat Information eXpression)</h4><p>Standard format for describing threat intelligence:</p><pre><code>{\n  \"type\": \"indicator\",\n  \"spec_version\": \"2.1\",\n  \"id\": \"indicator--8e2e2d2b-17d4-4cbf-938f-98ee46b3cd3f\",\n  \"created\": \"2024-01-15T00:00:00.000Z\",\n  \"modified\": \"2024-01-15T00:00:00.000Z\",\n  \"name\": \"Malicious IP\",\n  \"pattern\": \"[ipv4-addr:value = '192.168.50.100']\",\n  \"valid_from\": \"2024-01-15T00:00:00.000Z\",\n  \"labels\": [\"malicious-activity\"]\n}</code></pre><h4>TAXII (Trusted Automated eXchange of Intelligence Information)</h4><p>Protocol for exchanging STIX data:</p><ul><li><strong>Collections</strong>: Groups of related intelligence</li><li><strong>Channels</strong>: Publish/subscribe model</li><li><strong>API Roots</strong>: Entry points for TAXII services</li></ul><h4>TAXII Server Interaction</h4><pre><code># Discovery\nGET /taxii2/\n\n# Get collections\nGET /taxii2/collections/\n\n# Get objects from collection\nGET /taxii2/collections/{id}/objects/</code></pre>"
      },
      {
        "title": "Scheduled Feed Updates",
        "body": "<h4>Scripted Input for Feed Download</h4><p>Create inputs.conf entry:</p><pre><code>[script://./bin/fetch_threat_feed.py]\nindex = threat_intel\nsourcetype = threat_feed\ninterval = 3600\ndisabled = 0</code></pre><h4>Python Feed Fetcher Example</h4><pre><code>#!/usr/bin/env python\nimport requests\nimport csv\nimport sys\n\n# Fetch feed\nresponse = requests.get('https://feed.example.com/iocs.csv')\n\n# Parse and output\nreader = csv.DictReader(response.text.splitlines())\nfor row in reader:\n    print(f\"indicator={row['indicator']} type={row['type']} confidence={row['confidence']}\")</code></pre><h4>Scheduled Search for Feed Processing</h4><pre><code>| inputcsv https://feed.example.com/iocs.csv\n| eval first_seen = if(isnull(first_seen), strftime(now(), \"%Y-%m-%d\"), first_seen)\n| eval last_seen = strftime(now(), \"%Y-%m-%d\")\n| eval source = \"external_feed_name\"\n| outputlookup threat_intel_external.csv</code></pre><h4>Feed Update Frequency</h4><table><tr><th>Feed Type</th><th>Suggested Interval</th></tr><tr><td>Critical/Real-time</td><td>15-60 minutes</td></tr><tr><td>Daily feeds</td><td>Once daily</td></tr><tr><td>Weekly digests</td><td>Weekly</td></tr><tr><td>Slow-changing (GeoIP)</td><td>Monthly</td></tr></table>"
      },
      {
        "title": "Feed Normalization",
        "body": "<h4>The Normalization Challenge</h4><p>Different feeds use different schemas:</p><pre><code># Feed A\nip_address,category,score\n192.168.50.100,c2,90\n\n# Feed B  \nioc,ioc_type,confidence,tags\n192.168.50.100,ipv4,high,\"malware,c2\"\n\n# Feed C\nindicator,type,threat_level\n192.168.50.100,ip,critical</code></pre><h4>Standard Schema</h4><pre><code>indicator,type,confidence,category,source,first_seen,last_seen</code></pre><h4>Normalization Transforms</h4><pre><code># Feed A normalization\n| inputcsv feed_a.csv\n| rename ip_address as indicator\n| eval type = \"ip\"\n| eval confidence = case(score >= 80, \"high\", score >= 50, \"medium\", true(), \"low\")\n| rename category as category\n| eval source = \"feed_a\"\n| table indicator, type, confidence, category, source</code></pre><pre><code># Feed B normalization\n| inputcsv feed_b.csv\n| rename ioc as indicator, ioc_type as type\n| eval confidence = case(confidence=\"high\", \"high\", confidence=\"medium\", \"medium\", true(), \"low\")\n| rex field=tags \"(?&lt;category&gt;[^,]+)\"\n| eval source = \"feed_b\"\n| table indicator, type, confidence, category, source</code></pre><h4>Type Normalization</h4><pre><code>| eval type = case(\n    match(type, \"(?i)^(ip|ipv4|ip_address)$\"), \"ip\",\n    match(type, \"(?i)^(domain|fqdn|hostname)$\"), \"domain\",\n    match(type, \"(?i)^(md5|sha1|sha256|hash)$\"), \"hash\",\n    match(type, \"(?i)^(url|uri)$\"), \"url\",\n    true(), type)</code></pre>"
      },
      {
        "title": "Multi-Feed Aggregation",
        "body": "<h4>Combining Multiple Feeds</h4><pre><code>| inputlookup feed_a_normalized.csv\n| append [| inputlookup feed_b_normalized.csv]\n| append [| inputlookup feed_c_normalized.csv]\n| append [| inputlookup internal_iocs.csv]\n| dedup indicator\n| outputlookup combined_threat_intel.csv</code></pre><h4>Deduplication with Source Tracking</h4><pre><code>| inputlookup feed_a_normalized.csv | eval sources=\"feed_a\"\n| append [| inputlookup feed_b_normalized.csv | eval sources=\"feed_b\"]\n| append [| inputlookup feed_c_normalized.csv | eval sources=\"feed_c\"]\n| stats \n    values(sources) as sources,\n    max(confidence) as confidence,\n    min(first_seen) as first_seen,\n    max(last_seen) as last_seen,\n    values(category) as categories\n    by indicator, type\n| eval source_count = mvcount(sources)\n| outputlookup aggregated_threat_intel.csv</code></pre><h4>Confidence Aggregation</h4><pre><code>| eval confidence_score = case(\n    confidence=\"high\", 80,\n    confidence=\"medium\", 50,\n    confidence=\"low\", 20,\n    true(), 0)\n| stats \n    max(confidence_score) as max_confidence,\n    avg(confidence_score) as avg_confidence,\n    count as source_count\n    by indicator\n| eval final_confidence = case(\n    source_count >= 3 AND avg_confidence >= 50, \"high\",\n    source_count >= 2 OR max_confidence >= 80, \"medium\",\n    true(), \"low\")</code></pre>"
      },
      {
        "title": "Feed Quality Assessment",
        "body": "<h4>Feed Coverage Analysis</h4><pre><code>| inputlookup aggregated_threat_intel.csv\n| stats count by source\n| sort - count</code></pre><h4>Feed Overlap Analysis</h4><pre><code>| inputlookup aggregated_threat_intel.csv\n| eval source_count = mvcount(sources)\n| stats count by source_count\n| eval overlap = case(\n    source_count = 1, \"unique\",\n    source_count = 2, \"two_sources\",\n    source_count >= 3, \"multi_source\")</code></pre><h4>Feed Freshness</h4><pre><code>| inputlookup aggregated_threat_intel.csv\n| eval age_days = (now() - strptime(first_seen, \"%Y-%m-%d\")) / 86400\n| stats avg(age_days) as avg_age, max(age_days) as max_age, min(age_days) as min_age by sources\n| mvexpand sources\n| stats avg(avg_age) as avg_age by sources\n| sort avg_age</code></pre><h4>Feed Effectiveness</h4><pre><code>| inputlookup ti_alert_outcomes.csv\n| lookup aggregated_threat_intel.csv indicator OUTPUT sources\n| mvexpand sources\n| stats \n    count as alerts,\n    count(eval(outcome=\"true_positive\")) as tp,\n    count(eval(outcome=\"false_positive\")) as fp\n    by sources\n| eval tp_rate = round(tp / alerts * 100, 1)\n| sort - tp_rate</code></pre>"
      },
      {
        "title": "Feed Update Workflow",
        "body": "<h4>Complete Feed Refresh Workflow</h4><pre><code># Step 1: Fetch new feed data\n| inputcsv https://feed.example.com/latest.csv\n| eval fetch_time = now()\n\n# Step 2: Normalize\n| rename ioc as indicator, ioc_type as type\n| eval confidence = case(...)\n| eval source = \"feed_name\"\n\n# Step 3: Compare with existing\n| join type=left indicator [| inputlookup existing_feed.csv | fields indicator, first_seen]\n| eval first_seen = coalesce(first_seen, strftime(now(), \"%Y-%m-%d\"))\n| eval last_seen = strftime(now(), \"%Y-%m-%d\")\n\n# Step 4: Output\n| table indicator, type, confidence, category, source, first_seen, last_seen\n| outputlookup feed_name_normalized.csv</code></pre><h4>Incremental Updates</h4><pre><code># Only add new indicators\n| inputcsv https://feed.example.com/delta.csv\n| lookup existing_feed.csv indicator OUTPUT existing_indicator\n| where isnull(existing_indicator)\n| eval first_seen = strftime(now(), \"%Y-%m-%d\")\n| outputlookup append=t existing_feed.csv</code></pre><h4>Scheduled Aggregation</h4><pre><code># Run hourly to combine all feeds\n| inputlookup feed_a.csv | eval source=\"a\"\n| append [| inputlookup feed_b.csv | eval source=\"b\"]\n| append [| inputlookup internal.csv | eval source=\"internal\"]\n| stats values(source) as sources, max(confidence) as confidence by indicator, type\n| outputlookup master_threat_intel.csv</code></pre>"
      },
      {
        "title": "Error Handling and Monitoring",
        "body": "<h4>Feed Fetch Monitoring</h4><pre><code>index=_internal sourcetype=scheduler savedsearch_name=\"*feed*\"\n| stats latest(run_time) as last_run, latest(status) as status by savedsearch_name\n| eval hours_since_run = (now() - last_run) / 3600\n| where hours_since_run > 24 OR status != \"success\"</code></pre><h4>Feed Size Monitoring</h4><pre><code>| inputlookup master_threat_intel.csv\n| stats count as current_count\n| append [| inputlookup threat_intel_history.csv | where _time > relative_time(now(), \"-1d\") | stats latest(count) as previous_count]\n| eval change_pct = round((current_count - previous_count) / previous_count * 100, 1)\n| where abs(change_pct) > 20</code></pre><p>Alert if feed size changes dramatically.</p><h4>Feed Validation</h4><pre><code>| inputlookup master_threat_intel.csv\n| eval valid_ip = if(type=\"ip\", match(indicator, \"^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$\"), 1)\n| eval valid_domain = if(type=\"domain\", match(indicator, \"^[a-zA-Z0-9][a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\"), 1)\n| eval valid_hash = if(type=\"hash\", match(indicator, \"^[a-fA-F0-9]{32,64}$\"), 1)\n| where valid_ip=0 OR valid_domain=0 OR valid_hash=0\n| table indicator, type</code></pre>"
      },
      {
        "title": "Summary",
        "body": "<p>Key feed integration concepts:</p><ul><li><strong>STIX/TAXII</strong>: Industry standard for structured threat intelligence exchange</li><li><strong>Scheduled updates</strong>: Automated feed fetching at appropriate intervals</li><li><strong>Normalization</strong>: Convert diverse feed formats to standard schema</li><li><strong>Aggregation</strong>: Combine multiple feeds with deduplication and confidence tracking</li><li><strong>Quality metrics</strong>: Measure feed effectiveness, freshness, and overlap</li><li><strong>Monitoring</strong>: Track feed health, size changes, and validation errors</li></ul><p>Effective feed integration requires balancing coverage (more feeds) with quality (curated, validated intelligence).</p>"
      }
    ]
  }
}
